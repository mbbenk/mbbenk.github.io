<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Michaela B. Benk</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Manrope:wght@200;400;600;700&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css" crossorigin="anonymous" />

  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    body {
      font-family: 'Inter', sans-serif;
      background: #f2f4f8;
      color: #333;
      line-height: 1.7;
    }
    header {
      background: linear-gradient(to right, #2b2e4a, #e84545);
      color: black;
      padding: 4rem 1rem 3rem;
      text-align: center;
    }

    header h1 {
      font-size: 3rem;
      margin-bottom: 0.5rem;
      font-weight: 600;
      color: black;     
    letter-spacing: 0.3px;
    }

    header h1,
    .profile-text h1 {
      font-family: 'Manrope',sans-serif;
    }

    header h1,
    .profile-text h1 {
      font-family: 'Manrope', sans-serif;
      font-weight: 100; /* ExtraLight */
      font-size: 3.5rem; /* Signature feel */
      color: #960244;
      letter-spacing: 0.5px; /* Optional: subtle refinement */
    }


   header p {
    font-family: 'Manrope', sans-serif;
    font-weight: 500;
    font-size: 1.0rem;
    color: #555;
    margin-top: 0.5rem;
  }
    nav {
      background: white;
      padding: 1rem;
      text-align: center;
      position: sticky;
      top: 0;
      z-index: 1000;
      box-shadow: 0 3px 8px rgba(0,0,0,0.05);
    }
    nav a {
      margin: 0 1rem;
      text-decoration: none;
      color: #333;
      font-weight: 600;
      transition: all 0.3s ease;
    }
    nav a:hover {
      color: #e84545;
    }
    section {
      max-width: 900px;
      margin: 2rem auto;
      background: white;
      padding: 2.5rem;
      border-radius: 16px;
      box-shadow: 0 6px 18px rgba(0,0,0,0.07);
    }
    h2 {
      font-size: 1.8rem;
      color: #2b2e4a;
      margin-bottom: 1rem;
      border-bottom: 2px solid #e0e0e0;
      padding-bottom: 0.5rem;
    }
    ul {
      padding-left: 1.5rem;
    }
    footer {
      text-align: center;
      padding: 2rem 1rem;
      background: #f8f8f8;
      color: #666;
      font-size: 0.9rem;
      margin-top: 3rem;
    }
    a {
      color: #e84545;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .social-links {
      display: flex;
      justify-content: center;
      gap: 2rem;
      margin-top: 1.5rem;
      flex-wrap: wrap;
    }
    .social-links a {
      font-weight: 500;
      font-size: 1.1rem;
      color: #444;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      transition: color 0.3s;
    }
    .social-links a:hover {
      color: #e84545;
    }

    .profile-header {
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 2rem;
  padding: 3rem 1rem 2rem;
  background: #f2f4f8;
}

.profile-pic {
  width: 140px;
  height: 140px;
  border-radius: 50%;
  object-fit: cover;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}

.profile-text h1 {
  font-size: 2.5rem;
  margin-bottom: 0.5rem;
  font-weight: 600;
}

.profile-text p {
  font-size: 1.2rem;
  color: #555;
}

  </style>
</head>
<body>
<header class="profile-header">
  <img src="Me.jpg" alt="Your Name" class="profile-pic">
  <div class="profile-text">
    <h1>Michaela B. Benk</h1>
    <p>Dr. sc. ETH Zurich | Researcher in Human-Centered AI</p>
    
    <div class="social-links">
      <a href="https://www.linkedin.com/in/mbbenk" target="_blank">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://scholar.google.com/citations?user=hFdaRTMAAAAJ&hl=e" target="_blank">
        <i class="fas fa-graduation-cap"></i>
      </a>
      <a href="https://orcid.org/0000-0002-8171-320X" target="_blank">
        <i class="fab fa-orcid"></i>
      </a>
      <a href="mbbenk@gmail.com" target="_blank">
        <i class="fas fa-envelope"></i>
      </a>
    </div>
  </div>
</header>

  </header>
  <nav>
    <a href="#about">About</a>
    <a href="#news">News</a>
    <a href="#publications">Publications</a>
    <a href="#cv">CV</a>
  </nav>

  <section id="about">
    <p>
  I am an interdisciplinary researcher with a background in <strong>Computational Linguistics</strong> and <strong>Multilingual Text Analysis</strong>, and over <strong>eight years of experience in Human-Centered AI</strong>. I study how people make decisions, how AI systems influence those decisions, and what that means for society. I strongly believe that for AI systems to become valuable tools for all, humans (and not just the <a href="https://weirdpeople.fas.harvard.edu/qa-weird" target="_blank">WEIRD</a> ones) and their well-being must be central to their <strong>design</strong>, <strong>evaluation</strong>, and <strong>governance</strong>.
</p>
<br/>
<p>
  I have presented my work at <strong>top-tier international AI conferences</strong> and periodically contribute as an <strong>expert and speaker</strong> at international roundtables and AI forums. I am passionate about <strong>bridging communication and skill gaps</strong>, particularly at the intersection of <strong>AI and human rights</strong>.
</p>
<br/>
<p>
  I am always open to discussions, collaborations, and opportunities to expand my knowledge and impact in this exciting field. <strong>Feel free to connect</strong> with me to exchange ideas or explore potential collaborations.
</p>
  </section>


  <section id="news">
    <h2>News</h2>
    <li><strong>[July 2025]</strong> Join me at the AI for Good 2025 Global Summit. Excited to be participating in the workshop on AI for Human Rights: Smarter, Faster, Fairer Monitoring.
    </li>
    <li><strong>[March 2025]</strong> Happy to announce that I successfully passed my PhD defense!
      </li>
  </section>

  <section id="publications">
    <h2>Selected Publications</h2>
    <ul>
      <li><strong>[2025] Bridging the Knowledge Gap: Understanding User Expectations for Trustworthy LLM Standards</strong>. 
        Benk, M.,Wettstein, L., Schlicker, N.,Wangenheim, F., Scharowski, N. 
        AAAI Conference on Artificial Intelligence. 
    <br/>
      <strong>TL;DR:</strong> Mixed-methods web-based study (interviews N=12, survey N=379) identifying 68 user-centric trust criteria for LLMs. Reveals priorities for transparent governance, communication, and non-technical complements to techno-focused standards. </li>
<br/>
      <li><strong>[2024] Twenty-Four Years of Empirical Research on Trust in AI: A Bibliometric Review of Trends, Overlooked Issues, and Future Directions</strong>. 
        Benk, M., Kerstan, S., Wangenheim, F., Ferrario, A. 
        AI & Society
  <br/>
  <strong>TL;DR:</strong> Bibliometric and content analysis of 24 years of empirical literature on trust in AI.  <a href="https://link.springer.com/article/10.1007/s00146-024-02059-y">(link)</a>
</li>
<br/>
<li><strong>[2023]</strong> Certification Labels for Trustworthy AI: Insights From an Empirical Mixed-Method Study</strong>
  Scharowski, N., Benk, M., Kühne, S.J., Wettstein, L., Brühlmann, F. 
  Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT).
  <br/>
  <strong>TL;DR:</strong> User interviews (N=12) and survey (N=302) show certification labels boost trust and intent to use AI, especially in high‑stakes contexts. <a href="https://dl.acm.org/doi/10.1145/3593013.3593994">(link)</a>
<br/>
<li><strong>[2022] "Is It My Turn?" Assessing Teamwork and Taskwork in Collaborative Immersive Analytics</strong>\n
  Benk, M., Weibel, R., Feuerriegel, S., Ferrario, A. 
  Proceedings of the 25th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW).
  <br/>
  <strong>TL;DR:</strong> Empirical study of user collaboration in immersive analytics, investigating how teams navigate machine learning tasks in an immersive analytics environment. <a href="https://dl.acm.org/doi/abs/10.1145/3555580">(link)</a>
</li>
<br/>
<li><strong>[2022] Investigating Employees’ Concerns and Wishes Regarding Digital Stress Management Interventions With Value Sensitive Design: Mixed Methods Study</strong>, Kerr, J., Naegelin, M., Benk, M., Wangenheim, F., Meins, E., Viganò, E., Ferrario, A. Journal of Medical Internet Research.
  <br/>
  <strong>TL;DR:</strong> Mixed-method exploration using Value-Sensitive Design to uncover employee preferences and privacy concerns around digital stress management tools. <a href="https://www.jmir.org/2023/1/e44131/">(link)</a>
</li>
<br/>
<li><strong>[2021] The Value of Measuring Trust in AI – A Socio-Technical System Perspective</strong>, Benk, M., Tolmeijer, S., Wangenheim, F., Ferrario, A. CHI 2022 Workshop on Trust and Reliance in AI-Human Teams (TRAIT).
  <br/>
  <strong>TL;DR:</strong> Critiques the predominant focus on trust as an evaluation framework for AI research. Proposes a socio-technical systems approach to measuring trust, advocating for holistic assessment beyond individual-level metrics. <a href="https://arxiv.org/abs/2204.13480">(link)</a>
</li>
<br/>
<li><strong>[2021] Creative Uses of AI Systems and their Explanations: A Case Study from Insurance</strong>, Benk, M., Weibel, R., Ferrario, A. CHI 2022 Workshop on Human-Centered Explainable AI (HCXAI).
  <br/>
  <strong>TL;DR:</strong> Case study in insurance reveals novel creative workflows enabled by AI systems and explores how explanation mechanisms support users in these settings. <a href="https://arxiv.org/abs/2205.00931">(link)</a>
</li>
    </ul>
  </section>

    <section id="talks">
    <h2>Talks and Guest Lectures</h2>
    <ul>
<li><strong>[July 2025 (upcoming)] AI for Human Rights: Smarter, Faster, Fairer Monitoring</strong> (Invited Expert), AI for Good 2025 Global Summit.
  <br/>
  Topic: Leveraging artificial intelligence to improve speed, fairness, and effectiveness in global human rights monitoring.
</li>

<li><strong>[Nov 2024] Transparency Challenges in Human Rights Monitoring</strong> (Invited Speaker), GHRP Annual Conference – Expert Roundtable on Digital Human Rights Tracking Tools and Databases.
  <br/>
  Topic: Transparency issues and limitations in the use of digital tools and databases for human rights monitoring.
</li>

<li><strong>[Apr 2024] Guest Lecture on Human-Centered Explainable AI</strong> in course ‘KI und Ethik’, University of Basel.
  <br/>
  Topic: Basics on human-centered design principles in explainable AI and their ethical implications.
</li>

<li><strong>[Nov 2023] Welcoming Sentient AI</strong> (Panelist), Zurich Independent Art Exhibition.
  <br/>
  Topic: Artistic and philosophical perspectives on sentient AI and its societal impacts.
</li>

<li><strong>[May 2023] Explainability and Trust: The Importance of the Human Factor</strong> (Panelist), European Data Protection Supervisor IPEN event on Explainable Artificial Intelligence (XAI).
  <br/>
  Topic: Discussion on the critical role of human factors in the design and implementation of explainable AI systems.
</li>

<li><strong>[Sep 2022] Data Science zum Anfassen</strong> (Invited Speaker), Scientifica: Zurich Science Days.
  <br/>
  Topic: Making machine learning accessible and engaging for the public through interactive visual analytics. 

<li><strong>[Apr 2019] Monitoring Hate Speech Online</strong> (Invited Speaker), Annual meeting of the United Nations High Commissioner for Human Rights.
  <br/>
  Topic: Approaches and challenges in using machine learning to monitor hate speech online.
</li>


    </ul>
  </section>

  <section id="cv">
    <h2>CV</h2>
    <p><a href="CV.pdf" target="_blank">Download my CV (PDF)</a></p>
  </section>

  <footer>
    <p>&copy; 2025 Michaela Benk. All rights reserved.</p>
  </footer>
</body>
</html>
